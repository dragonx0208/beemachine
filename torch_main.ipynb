{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install validators\n",
    "#!pip install torch torchvision torchaudio\n",
    "#!pip install wget\n",
    "#%pip uninstall --yes torch torchvision torchaudio\n",
    "#%pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu115\n",
    "#%pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets, models\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.utils as vutils\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import gc\n",
    "import traceback\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "#device = torch.device(\"cpu\")\n",
    "print(f'Using {device} for inference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_resnet50', pretrained=True)\n",
    "utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_convnets_processing_utils')\n",
    "\n",
    "resnet50.eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = \"BeeMachine_quarter\"\n",
    "CATEGORIES = [\"Bombus_affinis\", \"Bombus_appositus\", \"Bombus_auricomus\", \"Bombus_bifarius\", \"Bombus_bimaculatus\", \"Bombus_borealis\", \n",
    "             \"Bombus_caliginosus\", \"Bombus_centralis\", \"Bombus_citrinus\", \"Bombus_crotchii\", \"Bombus_cryptarum\", \"Bombus_fernaldae_flavidus\", \n",
    "             \"Bombus_fervidus_californicus\", \"Bombus_flavifrons\", \"Bombus_fraternus\", \"Bombus_frigidus\", \"Bombus_griseocollis\", \"Bombus_huntii\", \n",
    "             \"Bombus_impatiens\", \"Bombus_insularis\", \"Bombus_melanopygus\", \"Bombus_mixtus\", \"Bombus_morrisoni\", \"Bombus_nevadensis\", \n",
    "             \"Bombus_occidentalis\", \"Bombus_pensylvanicus_sonorus\", \"Bombus_perplexus\",\"Bombus_rufocinctus\", \"Bombus_sandersoni\",\n",
    "             \"Bombus_sitkensis\", \"Bombus_sylvicola\", \"Bombus_ternarius\", \"Bombus_terricola\", \"Bombus_vagans\", \"Bombus_vandykei\", \n",
    "             \"Bombus_vosnesenskii\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "def load_dataset(is_simple_transform=True):\n",
    "    if is_simple_transform:\n",
    "        transformer = transforms.Compose([\n",
    "            transforms.Resize((224,224)),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "    else:\n",
    "        transformer = transforms.Compose([\n",
    "            transforms.Resize((224,224)),\n",
    "            transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.4904, 0.4515, 0.3639],\n",
    "                                    std=[0.2403, 0.2280, 0.2248])\n",
    "        ])\n",
    "    \n",
    "    #Load image\n",
    "    dataset = datasets.ImageFolder(root=f'{DATADIR}', transform=transformer)\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_mean_std(dataset):\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=8)\n",
    "    nimages = 0\n",
    "    mean = 0.\n",
    "    std = 0.\n",
    "    for batch, _ in loader:\n",
    "        # Rearrange batch to be the shape of [B, C, W * H]\n",
    "        batch = batch.view(batch.size(0), batch.size(1), -1)\n",
    "        # Update total number of images\n",
    "        nimages += batch.size(0)\n",
    "        # Compute mean and std here\n",
    "        mean += batch.mean(2).sum(0) \n",
    "        std += batch.std(2).sum(0)\n",
    "\n",
    "    # Final step\n",
    "    mean /= nimages\n",
    "    std /= nimages\n",
    "\n",
    "    print(mean)\n",
    "    print(std)\n",
    "\n",
    "#find_mean_std(bee_dataset)\n",
    "# mean tensor([0.4904, 0.4515, 0.3639])\n",
    "# std tensor([0.2403, 0.2280, 0.2248])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate data to train and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bee_dataset = load_dataset(is_simple_transform=False)\n",
    "\n",
    "num_classes=len(bee_dataset.targets)\n",
    "train_indices, val_indices = train_test_split(list(range(num_classes)), test_size=0.2, stratify=bee_dataset.targets)\n",
    "train_dataset = torch.utils.data.Subset(bee_dataset, train_indices)\n",
    "val_dataset = torch.utils.data.Subset(bee_dataset, val_indices)\n",
    "resnet50.fc = nn.Sequential(\n",
    "               nn.Linear(2048, 224),\n",
    "               nn.Dropout(p=0.02),\n",
    "               nn.ReLU(inplace=True),\n",
    "               nn.Linear(224, 45),\n",
    "               nn.Softmax()).to(device) \n",
    "torch.autograd.set_detect_anomaly(True)               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "print(torch.cuda.memory_allocated(device))\n",
    "val_data_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "print(torch.cuda.memory_allocated(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some training images\n",
    "real_batch = next(iter(train_data_loader))\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = class_weight.compute_class_weight('balanced', np.unique(bee_dataset.targets), bee_dataset.targets)\n",
    "class_weights=torch.tensor(np.unique(bee_dataset.targets),dtype=torch.float).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(class_weights)\n",
    "optimizer = optim.SGD(resnet50.fc.parameters(), lr=0.0001, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1\n",
    "valid_loss_min = np.Inf\n",
    "val_loss = []\n",
    "val_acc = []\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "total_step = len(train_dataset)\n",
    "\n",
    "def train_model(model, dataloaders, criterion, optimizer, train_loss, train_acc, total_step, num_epochs=3):\n",
    "    os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total=0\n",
    "        model.train()\n",
    "        print(f'Epoch {epoch}\\n')\n",
    "        for batch_idx, (data_, target_) in enumerate(dataloaders):\n",
    "            data_, target_ = data_.to(device), target_.to(device)            \n",
    "            outputs = model(data_)\n",
    "            loss = criterion(outputs, target_)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _,pred = torch.max(outputs, dim=1)\n",
    "            correct += torch.sum(pred==target_).item()\n",
    "            total += target_.size(0)\n",
    "            #print(\"matrix predict {} target {}\".format(pred, target_))\n",
    "            if (batch_idx) % 20 == 0:\n",
    "                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                    .format(epoch, n_epochs, batch_idx * 32, total_step, loss.item()))\n",
    "        train_acc.append(100 * correct / total)\n",
    "        train_loss.append(running_loss/total_step)\n",
    "        print(f'\\ntrain-loss: {np.mean(train_loss):.4f}, train-acc: {(100 * correct/total):.4f}')\n",
    "        \n",
    "        validate_model(model_trained, val_data_loader, valid_loss_min, val_loss, val_acc)\n",
    "                  \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(model, dataloaders, valid_loss_min, val_loss, val_acc):\n",
    "    batch_loss = 0\n",
    "    total_t=0\n",
    "    correct_t=0\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for data_, target_ in dataloaders:\n",
    "            data_t, target_t = data_.to(device), target_.to(device)\n",
    "            outputs_t = model(data_t)\n",
    "            loss_t = criterion(outputs_t, target_t)\n",
    "            batch_loss += loss_t.item()\n",
    "            _,pred_t = torch.max(outputs_t, dim=1)\n",
    "            #print(\"predict {} target {}\".format(len(pred_t), len(target_t)))\n",
    "            #print(\"matrix predict {} target {}\".format(pred_t, target_t))\n",
    "            correct_t += torch.sum(pred_t==target_t).item()\n",
    "            total_t += target_t.size(0)\n",
    "        val_acc.append(100 * correct_t/total_t)\n",
    "        val_loss.append(batch_loss/len(dataloaders))\n",
    "        network_learned = batch_loss < valid_loss_min\n",
    "        print(f'validation loss: {np.mean(val_loss):.4f}, validation acc: {(100 * correct_t/total_t):.4f}\\n')\n",
    "        \n",
    "        if network_learned:\n",
    "            modelPath = 'models/pytorch'\n",
    "            isExist = os.path.exists(modelPath)\n",
    "            if not isExist:\n",
    "                # Create a new directory because it does not exist \n",
    "                os.makedirs(modelPath)\n",
    "                print(\"The new directory {} is created!\".format(modelPath))\n",
    "            valid_loss_min = batch_loss\n",
    "            torch.save(model.state_dict(), 'models/pytorch/traiend_resnet50.h5')\n",
    "            print('Improvement-Detected, save-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_confusion_matrix(model, labels, pred_labels):\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    cm = confusion_matrix(labels, pred_labels)\n",
    "    cm = ConfusionMatrixDisplay(cm, display_labels=range(10))\n",
    "    cm.plot(values_format='d', cmap='Blues', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "\n",
      "Epoch [1/1], Step [0/31848], Loss: 3.8069\n",
      "Epoch [1/1], Step [640/31848], Loss: 3.8072\n",
      "Epoch [1/1], Step [1280/31848], Loss: 3.8071\n",
      "Epoch [1/1], Step [1920/31848], Loss: 3.8070\n",
      "Epoch [1/1], Step [2560/31848], Loss: 3.8069\n",
      "Epoch [1/1], Step [3200/31848], Loss: 3.8070\n",
      "Epoch [1/1], Step [3840/31848], Loss: 3.8066\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    model_trained = train_model(resnet50, train_data_loader, criterion, optimizer, train_loss, train_acc, total_step, n_epochs)\n",
    "except Exception:\n",
    "    print(traceback.format_exc())\n",
    "    print(torch.cuda.memory_summary(device=None, abbreviated=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.title(\"Train-Validation Accuracy\")\n",
    "plt.plot(train_acc, label='train')\n",
    "plt.plot(val_acc, label='validation')\n",
    "plt.xlabel('num_epochs', fontsize=12)\n",
    "plt.ylabel('accuracy', fontsize=12)\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_resnet50', pretrained=False)\n",
    "resnet50.load_state_dict(torch.load('models/pytorch/traiend_resnet50.h5'))                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## OVER SAMPLEING ## \n",
    "\n",
    "\n",
    "TEST Github+\n",
    "TRY +1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yelei Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
