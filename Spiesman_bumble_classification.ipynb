{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional neural network for bumble bee species ID from images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: tensorflow 2.8.0\n",
      "Uninstalling tensorflow-2.8.0:\n",
      "  Successfully uninstalled tensorflow-2.8.0\n",
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.8.0-cp38-cp38-macosx_10_14_x86_64.whl (217.4 MB)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/chingyingkuo/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.24.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/chingyingkuo/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/chingyingkuo/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/chingyingkuo/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/chingyingkuo/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/chingyingkuo/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/chingyingkuo/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /Users/chingyingkuo/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.22.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/chingyingkuo/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.7.4.2)\n",
      "Requirement already satisfied: gast>=0.2.1 in /Users/chingyingkuo/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in /Users/chingyingkuo/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/chingyingkuo/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.44.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /Users/chingyingkuo/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.20.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/chingyingkuo/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /Users/chingyingkuo/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: setuptools in /Users/chingyingkuo/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (49.2.0.post20200714)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /Users/chingyingkuo/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (13.0.0)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in /Users/chingyingkuo/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /Users/chingyingkuo/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /Users/chingyingkuo/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /Users/chingyingkuo/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/chingyingkuo/opt/anaconda3/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow) (0.34.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/chingyingkuo/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/chingyingkuo/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.24.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/chingyingkuo/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/chingyingkuo/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/chingyingkuo/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/chingyingkuo/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/chingyingkuo/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/chingyingkuo/opt/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/chingyingkuo/opt/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/chingyingkuo/opt/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/chingyingkuo/opt/anaconda3/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/chingyingkuo/opt/anaconda3/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/chingyingkuo/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/chingyingkuo/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/chingyingkuo/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/chingyingkuo/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.25.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/chingyingkuo/opt/anaconda3/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/chingyingkuo/opt/anaconda3/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/chingyingkuo/opt/anaconda3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.1.0)\n",
      "Installing collected packages: tensorflow\n",
      "Successfully installed tensorflow-2.8.0\n"
     ]
    }
   ],
   "source": [
    "#!conda uninstall --yes keras\n",
    "#!pip uninstall --yes keras\n",
    "\n",
    "!pip uninstall --yes tensorflow\n",
    "!pip install tensorflow\n",
    "#!pip install opencv-python\n",
    "\n",
    "#!pip install keras==2.3.1\n",
    "#!pip install keras_preprocessing \n",
    "#!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf # I'm using tf v1.13.1\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import random\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization, ZeroPadding2D, AveragePooling2D\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up data directory and names of species included in the classification model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = \"/Users/chingyingkuo/Downloads/BeeMachine_quarter\"\n",
    "CATEGORIES = [\"Bombus_affinis\", \"Bombus_appositus\", \"Bombus_auricomus\", \"Bombus_bifarius\", \"Bombus_bimaculatus\", \"Bombus_borealis\", \n",
    "             \"Bombus_caliginosus\", \"Bombus_centralis\", \"Bombus_citrinus\", \"Bombus_crotchii\", \"Bombus_cryptarum\", \"Bombus_fernaldae_flavidus\", \n",
    "             \"Bombus_fervidus_californicus\", \"Bombus_flavifrons\", \"Bombus_fraternus\", \"Bombus_frigidus\", \"Bombus_griseocollis\", \"Bombus_huntii\", \n",
    "             \"Bombus_impatiens\", \"Bombus_insularis\", \"Bombus_melanopygus\", \"Bombus_mixtus\", \"Bombus_morrisoni\", \"Bombus_nevadensis\", \n",
    "             \"Bombus_occidentalis\", \"Bombus_pensylvanicus_sonorus\", \"Bombus_perplexus\",\"Bombus_rufocinctus\", \"Bombus_sandersoni\",\n",
    "             \"Bombus_sitkensis\", \"Bombus_sylvicola\", \"Bombus_ternarius\", \"Bombus_terricola\", \"Bombus_vagans\", \"Bombus_vandykei\", \n",
    "             \"Bombus_vosnesenskii\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set number of classes (species) and image size (number of pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(CATEGORIES)\n",
    "IMG_SIZE = 299 #length and width of input images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "img_filenames = []\n",
    "def create_training_data():\n",
    "    image_cap = 200\n",
    "    for category in CATEGORIES:\n",
    "      path=os.path.join(DATADIR,category)\n",
    "      class_num = CATEGORIES.index(category)\n",
    "      cnt = 0  \n",
    "      for img in os.listdir(path):\n",
    "        try:\n",
    "            img_array = cv2.imread(os.path.join(path,img))\n",
    "            new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "            new_array = cv2.cvtColor(new_array, cv2.COLOR_BGR2RGB)\n",
    "            training_data.append([new_array, class_num])\n",
    "            img_filenames.append(os.path.join(path,img))\n",
    "            cnt = cnt + 1\n",
    "        except Exception as e:\n",
    "            pass\n",
    "        if cnt >= image_cap:\n",
    "            break\n",
    "create_training_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up and resize the image arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for features, label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "\n",
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2, random_state=42) #split into training and test data\n",
    "img_file_train, img_file_test = train_test_split(img_filenames, test_size=0.2, random_state=42) #split into training and test data\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data are imbalanaced. Set up class weights to help account for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "weights_dict = dict(enumerate(weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set batch size and data augmentation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rotation_range=100,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.3,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.python.keras.layers' has no attribute 'BatchNormalization'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-0982f54ef583>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# InceptionV3 performed best of the models above\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mbase_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInceptionV3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpooling\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m'avg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMG_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMG_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/applications/inception_v3.py\u001b[0m in \u001b[0;36mInceptionV3\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/applications/inception_v3.py\u001b[0m in \u001b[0;36mconv2d_bn\u001b[0;34m(x, filters, num_row, num_col, padding, strides, name)\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.python.keras.layers' has no attribute 'BatchNormalization'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications import InceptionResNetV2\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "\n",
    "# InceptionV3 performed best of the models above \n",
    "base_model = InceptionV3(include_top=False, pooling ='avg', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "x = base_model.output\n",
    "x = Dense(1000, activation='relu')(x)\n",
    "x = Dropout(0.06)(x)\n",
    "x = Dense(1000, activation='relu')(x)\n",
    "x = Dropout(0.06)(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs = base_model.input, outputs = predictions)\n",
    "\n",
    "# Summarize the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up early stopping, save best model, adjust learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
    "mcp_save = ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, min_delta=1e-4, mode='min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top-3 accuracy can be included in metrics\n",
    "top3_acc = functools.partial(keras.metrics.sparse_top_k_categorical_accuracy, k=3)\n",
    "top3_acc.__name__ = 'top3_acc'\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "              optimizer=\"sgd\", \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_epocs = 50\n",
    "history = model.fit_generator(train_datagen.flow(X_train, y_train, batch_size=batch_size),\n",
    "                              steps_per_epoch = X_train.shape[0] // batch_size,\n",
    "                              epochs=num_epocs,\n",
    "                              validation_data=(X_test, y_test),  \n",
    "                              verbose=1,\n",
    "                              class_weight=weights_dict,\n",
    "                              callbacks=[mcp_save, reduce_lr_loss],\n",
    "                              use_multiprocessing=False,\n",
    "                              workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_x_date.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot loss and accuracy\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_labels)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "print ('Accuracy Score:',accuracy_score(y_test, y_pred_labels))\n",
    "print(classification_report(y_test, y_pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at a random test image and see prediction results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "num_images = 1\n",
    "rand_images = []\n",
    "for i in range(0,num_images):\n",
    "    n = random.randint(1,15431)\n",
    "    rand_images.append(n)\n",
    "\n",
    "for x in rand_images:\n",
    "    y_pred = model.predict(X_test[[x]])\n",
    "    y_pred_labels = np.argmax(y_pred)\n",
    "    plt.imshow(X_test[x])\n",
    "    print('Test image:',x)\n",
    "    print('True species:',CATEGORIES[y_test[x]])\n",
    "    print('Predicted species:',CATEGORIES[y_pred_labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make table of misclassified images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_image = ['Test image']\n",
    "true_species = ['True species']\n",
    "pred_species = ['Predicted species']\n",
    "probability = ['Probability']\n",
    "img_file_name = ['File name']\n",
    "\n",
    "test_images = list(range(len(X_test)))\n",
    "for x in test_images:\n",
    "    y_pred = model.predict(X_test[[x]])\n",
    "    y_pred_labels = np.argmax(y_pred)\n",
    "    if y_test[x] != y_pred_labels:\n",
    "        test_image.append(x)\n",
    "        true_species.append(CATEGORIES[y_test[x]])\n",
    "        pred_species.append(CATEGORIES[y_pred_labels])\n",
    "        probability.append(max(max(model.predict(X_test[[x]]))))\n",
    "        img_file_name.append(img_file_test[x])\n",
    "\n",
    "true_pred_species = list(zip(test_image, true_species, pred_species, probability, img_file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save misclassification table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('true_pred_species', true_pred_species, fmt='%s', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display image and results from a particular test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_num = 221\n",
    "y_pred = model.predict(X_test[[image_num]])\n",
    "y_pred_labels = np.argmax(y_pred)\n",
    "plt.imshow(X_test[image_num])\n",
    "print('Test image:',image_num)\n",
    "print('True species:',CATEGORIES[y_test[image_num]])\n",
    "print('Predicted species:',CATEGORIES[y_pred_labels])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
