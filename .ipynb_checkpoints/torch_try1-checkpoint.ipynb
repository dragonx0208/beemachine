{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wget in /Users/chingyingkuo/opt/anaconda3/lib/python3.8/site-packages (3.2)\r\n"
     ]
    }
   ],
   "source": [
    "#!pip install torch torchvision torchaudio\n",
    "!pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/chingyingkuo/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /Users/chingyingkuo/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b6a66ef2d594eefbc85c012a6752459",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=102530333.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "url, filename = (\"https://www.akc.org/wp-content/uploads/2017/11/German-Shepherd-on-White-00.jpg\", \"dog3.jpg\")\n",
    "try: urllib.URLopener().retrieve(url, filename)\n",
    "except: urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = \"/Users/chingyingkuo/Downloads/BeeMachine_quarter\"\n",
    "CATEGORIES = [\"Bombus_affinis\", \"Bombus_appositus\", \"Bombus_auricomus\", \"Bombus_bifarius\", \"Bombus_bimaculatus\", \"Bombus_borealis\", \n",
    "             \"Bombus_caliginosus\", \"Bombus_centralis\", \"Bombus_citrinus\", \"Bombus_crotchii\", \"Bombus_cryptarum\", \"Bombus_fernaldae_flavidus\", \n",
    "             \"Bombus_fervidus_californicus\", \"Bombus_flavifrons\", \"Bombus_fraternus\", \"Bombus_frigidus\", \"Bombus_griseocollis\", \"Bombus_huntii\", \n",
    "             \"Bombus_impatiens\", \"Bombus_insularis\", \"Bombus_melanopygus\", \"Bombus_mixtus\", \"Bombus_morrisoni\", \"Bombus_nevadensis\", \n",
    "             \"Bombus_occidentalis\", \"Bombus_pensylvanicus_sonorus\", \"Bombus_perplexus\",\"Bombus_rufocinctus\", \"Bombus_sandersoni\",\n",
    "             \"Bombus_sitkensis\", \"Bombus_sylvicola\", \"Bombus_ternarius\", \"Bombus_terricola\", \"Bombus_vagans\", \"Bombus_vandykei\", \n",
    "             \"Bombus_vosnesenskii\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(CATEGORIES)\n",
    "IMG_SIZE = 299 #length and width of input images\n",
    "filename=\"bee.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.6548e-01, -2.8433e+00, -2.7145e+00, -7.2382e-01, -2.7915e+00,\n",
      "        -1.8500e+00, -3.3788e+00, -1.7761e-01,  2.4291e-01, -7.6931e-01,\n",
      "        -1.6631e+00, -2.5720e+00, -3.1983e+00, -2.5533e+00, -3.0038e+00,\n",
      "        -3.2977e+00, -1.8944e+00, -3.8531e-01, -1.7407e+00, -2.0156e+00,\n",
      "        -3.6446e+00, -1.4941e+00, -2.9115e+00, -1.4359e+00, -3.7127e+00,\n",
      "        -1.1858e+00, -3.3835e+00, -3.0889e+00, -2.5367e+00, -2.4035e+00,\n",
      "        -2.8510e+00, -2.9343e+00, -3.2970e+00, -4.8861e-01, -1.2813e+00,\n",
      "        -6.7678e-01, -1.4731e+00, -1.3160e+00, -1.0851e+00, -1.6318e+00,\n",
      "        -1.9022e+00, -2.4195e+00, -1.5093e+00, -1.5429e+00, -1.0064e+00,\n",
      "        -7.5844e-01, -2.2677e+00, -2.1452e+00, -3.2198e+00, -2.5348e+00,\n",
      "         2.1965e-01, -4.5840e-01, -1.2581e+00, -2.7080e+00, -2.5305e-01,\n",
      "        -2.1414e+00, -3.0574e+00, -2.1760e+00, -1.1541e+00, -1.3986e+00,\n",
      "         4.3393e-01, -9.8081e-02, -4.3213e-01, -7.9929e-02, -2.7738e+00,\n",
      "        -4.5491e-01, -1.0131e+00, -1.6058e+00, -1.1018e+00, -2.5184e+00,\n",
      "        -1.9923e+00,  9.6740e-01, -3.0304e+00, -2.8227e+00, -2.3530e+00,\n",
      "        -3.5910e+00, -2.3232e+00, -1.1570e+00, -4.6064e-01, -1.3944e+00,\n",
      "        -6.1173e-01, -4.2559e+00, -2.3433e+00, -1.3639e+00, -8.7673e-01,\n",
      "        -2.9242e+00, -2.2457e+00, -3.4061e+00, -2.6362e+00, -3.1360e+00,\n",
      "        -2.3442e+00, -1.2032e+00, -1.8005e+00, -2.1730e+00, -2.3092e+00,\n",
      "        -2.4118e+00, -3.0014e+00, -4.4305e-01, -1.7140e+00, -6.9318e-01,\n",
      "        -3.5781e-01, -1.3685e+00, -3.6435e+00, -1.7781e+00,  1.4611e+00,\n",
      "        -2.6507e+00,  2.5608e-01, -2.5828e+00, -1.6632e+00, -1.6093e+00,\n",
      "        -3.6198e+00, -1.1225e+00,  3.6798e-01, -1.3585e+00, -5.6838e-01,\n",
      "        -1.8375e+00, -4.9766e-01, -2.1416e+00, -1.2588e-02, -1.5801e+00,\n",
      "        -2.9400e+00, -7.7389e-01,  7.3163e-03, -1.4950e+00, -5.8562e-01,\n",
      "        -3.0679e+00, -1.0822e+00, -1.6727e+00, -2.5372e+00, -2.4061e+00,\n",
      "        -2.1191e+00, -3.0288e+00, -3.9127e+00,  5.5617e-01, -2.6187e+00,\n",
      "        -3.4067e+00, -4.1803e-01, -2.5448e+00, -2.8422e+00, -2.8191e+00,\n",
      "        -3.4792e+00, -4.2153e+00, -1.1401e+00, -2.0136e+00, -2.2442e+00,\n",
      "        -1.5146e+00, -2.3905e+00, -2.3719e+00, -2.5217e+00, -4.2448e+00,\n",
      "        -6.8761e-01,  3.1765e+00, -1.3701e+00, -2.4977e+00, -3.6356e-01,\n",
      "        -1.2649e+00, -1.0199e+00, -9.0608e-01,  1.9632e+00,  4.2272e+00,\n",
      "         3.1146e+00,  3.0674e+00,  1.6851e+00,  7.6112e+00,  2.2179e+00,\n",
      "         3.3895e+00,  6.6134e-01,  3.3176e+00,  2.3890e+00,  2.9166e+00,\n",
      "         4.2925e+00, -1.0173e+00,  1.4087e+00,  3.2332e+00,  5.3221e+00,\n",
      "         5.8377e+00,  2.4625e+00,  1.1683e+00, -4.0759e-01,  1.6259e+00,\n",
      "         2.9926e+00, -1.0337e-01,  4.9402e+00,  2.1675e-01,  4.7984e+00,\n",
      "         5.3406e+00,  6.1752e+00,  2.0355e+00,  4.1590e+00,  6.3294e+00,\n",
      "        -5.5754e-01,  7.1469e+00,  3.3708e+00,  7.2400e+00,  2.7760e+00,\n",
      "         2.5858e+00,  7.3786e-01,  2.5244e+00,  1.3036e+00,  4.0598e+00,\n",
      "         2.0818e+00,  2.9401e+00,  2.6760e+00, -3.4470e-01,  2.1039e-01,\n",
      "         1.5481e+00,  1.4533e+00,  3.5002e+00,  1.8312e+00,  3.1107e+00,\n",
      "        -1.9439e+00,  1.1661e+00, -7.5548e-01,  2.5024e+00,  3.2541e+00,\n",
      "         2.7536e-01,  1.6988e+00, -5.0402e-01,  1.5837e+00,  2.1828e+00,\n",
      "         2.5667e+00, -2.8405e-01,  2.4164e+00,  1.8595e+00,  4.2722e+00,\n",
      "         7.8847e+00,  4.6958e+00,  6.4320e+00, -4.1986e-01,  1.0733e+00,\n",
      "         1.3935e+00,  4.1460e+00,  2.4368e+00,  1.7441e+00,  5.7025e+00,\n",
      "         1.5387e+01,  4.0855e+00,  7.1091e-01,  1.6905e+00,  9.5859e-01,\n",
      "         3.5297e+00,  3.7744e-02, -6.6720e-01,  3.6911e+00,  4.6490e+00,\n",
      "         9.6304e-01,  3.3423e+00,  3.5393e+00,  4.5366e+00,  3.4170e+00,\n",
      "         3.0145e+00, -3.8355e-01, -8.1073e-01,  1.4163e+00,  2.8160e-01,\n",
      "         5.5952e+00,  2.7958e+00, -2.0872e-01, -7.3764e-01,  9.2984e-01,\n",
      "         3.4609e+00,  1.6577e+00,  3.1396e+00,  3.9352e+00,  5.0839e+00,\n",
      "        -5.6714e-01,  2.1395e-01,  1.7209e+00,  7.1368e-01,  2.1131e+00,\n",
      "         9.4811e-01,  3.5931e+00,  1.9367e-01,  4.3227e+00,  3.5910e+00,\n",
      "         2.4011e+00,  2.0053e-01,  2.5674e-02,  6.9011e-01, -2.8667e+00,\n",
      "         5.7496e-02,  2.6903e+00,  2.0401e+00, -4.3234e-01,  2.1201e+00,\n",
      "         1.4253e+00,  2.1439e-01, -8.8034e-01, -1.0741e+00, -2.0036e+00,\n",
      "        -1.3230e+00,  2.3433e+00,  2.6801e-01, -9.8274e-01,  4.0593e-01,\n",
      "         1.1465e-01, -1.1477e+00, -3.0955e+00, -3.1707e+00, -1.3889e+00,\n",
      "        -1.8899e+00, -2.5341e+00, -1.4206e+00, -1.7021e+00, -1.4175e+00,\n",
      "        -9.1607e-01, -1.0437e+00, -2.3683e+00, -2.4849e+00, -6.9844e-01,\n",
      "        -2.9539e+00, -7.0319e-01, -7.3501e-01, -2.0299e+00,  6.4817e-01,\n",
      "        -3.0221e+00, -2.4435e+00, -1.5985e+00, -2.9556e+00, -2.6089e+00,\n",
      "        -2.8977e+00, -8.6503e-01, -2.8201e+00, -2.4729e+00, -3.7991e+00,\n",
      "        -2.3537e+00, -1.8009e+00, -3.0412e-01, -1.8872e+00, -1.5232e+00,\n",
      "        -1.9491e+00,  1.4596e+00, -1.6703e+00, -1.0252e+00, -3.4487e+00,\n",
      "        -2.7196e+00, -2.0387e+00, -5.5521e-01, -6.6006e-01, -1.4772e+00,\n",
      "        -4.1297e-01,  6.9173e-01,  1.6353e-02, -2.8294e+00, -2.6884e+00,\n",
      "        -2.0293e+00, -7.1922e-01, -2.0913e+00, -1.1316e+00, -2.8368e+00,\n",
      "        -7.5981e-01, -6.7071e-01, -1.5708e+00, -1.2339e+00,  8.9959e-01,\n",
      "         9.6820e-01, -6.4440e-03, -1.1732e+00, -6.5511e-01,  1.5611e-02,\n",
      "        -1.8923e+00, -2.7765e+00, -1.0048e+00, -1.3631e+00, -1.7631e+00,\n",
      "        -1.7405e+00, -3.9960e+00, -1.6025e+00, -4.3823e-01, -2.5883e+00,\n",
      "        -2.6063e+00, -1.7006e+00, -2.5108e+00, -1.5629e+00, -3.4387e+00,\n",
      "        -3.0987e+00, -1.9443e+00, -3.6117e+00,  1.5797e-01, -7.5102e-01,\n",
      "        -3.5016e+00, -2.6921e+00, -2.9374e+00, -3.6272e+00, -7.5613e-01,\n",
      "        -6.0979e-01, -2.9692e+00, -3.2202e+00, -8.2406e-01, -1.5602e-01,\n",
      "        -7.5036e-01, -1.3244e+00, -6.3528e-01, -4.1524e+00, -3.2355e-01,\n",
      "        -1.0954e+00, -2.0832e+00, -3.9536e+00, -1.5044e+00,  3.6892e-01,\n",
      "         1.6922e+00,  5.3889e-02, -2.9571e-01, -5.0970e-01, -1.9035e+00,\n",
      "        -7.6636e-01, -2.8970e-01, -1.3264e+00,  4.7395e-01,  1.2042e+00,\n",
      "        -2.2364e+00, -1.7696e-01,  1.9036e+00,  4.8289e-01,  3.3475e+00,\n",
      "        -1.4417e+00, -1.2922e+00,  1.1303e+00, -1.1426e-01, -1.0076e+00,\n",
      "         7.6017e-01,  7.6269e-01,  7.1230e-01, -6.2165e-01, -1.6597e+00,\n",
      "        -1.9336e+00, -1.6179e-01,  9.1968e-01,  3.3089e+00,  2.5096e+00,\n",
      "         8.7244e-01,  1.0261e+00, -2.8265e+00,  2.0908e+00,  1.4719e+00,\n",
      "         1.0674e+00, -7.3288e-01,  2.6253e-01, -6.1517e-01,  1.3185e+00,\n",
      "         3.7864e-01, -1.3735e+00, -2.5610e-01,  6.5960e-01, -6.4972e-01,\n",
      "         3.7175e-01,  6.9264e-01,  1.5090e-01, -3.0165e-01, -2.6154e-01,\n",
      "        -1.8538e-01,  3.2805e-01,  3.5636e-01,  1.3879e+00,  9.3847e-01,\n",
      "        -3.3394e-02, -1.5503e+00,  2.4100e+00,  6.9606e-01,  1.1140e+00,\n",
      "         8.5763e-01, -4.2521e-01, -2.7677e-01,  2.6027e+00,  1.0199e+00,\n",
      "         5.6375e+00, -1.1473e+00,  5.5693e-01, -1.5711e-01,  2.1288e-01,\n",
      "         1.6200e-01,  1.6139e-01,  1.1345e+00, -2.8749e-01, -1.4859e+00,\n",
      "         4.3445e-01, -2.3183e+00, -1.1957e+00, -3.2022e-01,  1.8749e+00,\n",
      "        -4.6207e-01,  3.0632e-01,  1.0623e+00,  2.9252e-01, -6.2848e-01,\n",
      "         1.0153e+00, -2.2917e+00,  4.4146e+00,  1.2849e+00, -1.1585e+00,\n",
      "        -3.4644e-03,  6.8260e-02, -4.1475e-01, -1.2782e-01, -1.0467e+00,\n",
      "        -3.6092e-01, -1.6265e-01, -2.3676e-01, -2.6581e+00,  7.8008e-01,\n",
      "        -1.9343e+00, -9.1777e-01,  2.2377e+00, -9.2018e-02,  7.8303e-02,\n",
      "         6.0091e-01,  5.6096e-01,  2.3068e-01,  2.0192e+00, -1.2004e+00,\n",
      "         2.5491e+00, -6.4829e-01,  1.4119e+00,  4.4324e-01,  3.5000e+00,\n",
      "         2.9247e+00,  5.7534e-01,  1.1457e+00,  3.0302e+00,  6.6361e-01,\n",
      "        -5.1544e-01,  4.2099e-01,  5.6050e-01,  8.3964e-01, -4.1753e-01,\n",
      "        -1.6337e+00,  6.1680e-01,  1.0367e+00, -5.1975e-01, -1.0446e+00,\n",
      "         1.1739e+00,  3.0084e+00,  1.4069e+00,  3.6534e-02, -3.9786e-01,\n",
      "        -5.2716e-01,  2.3172e+00,  3.2494e+00, -3.0436e-02,  3.3587e+00,\n",
      "        -1.0751e+00,  1.8571e+00, -9.9130e-02,  3.4805e+00,  2.3027e+00,\n",
      "         1.7103e-02,  1.2384e+00, -1.8814e+00,  3.6242e-01, -4.7309e-01,\n",
      "        -1.5081e+00,  9.4683e-01,  1.9730e+00,  1.4970e-01, -9.2947e-01,\n",
      "        -2.4883e+00,  1.3729e+00,  3.9018e-01, -1.9245e+00,  2.7633e+00,\n",
      "         5.1745e-01, -5.3223e-01,  9.0086e-01,  4.4600e-01, -2.3276e+00,\n",
      "        -3.9396e-02, -3.3314e-01,  3.3810e+00,  1.5128e+00, -1.5005e+00,\n",
      "         8.8134e-01, -2.4630e+00,  1.2504e+00, -1.1035e+00,  2.6315e+00,\n",
      "        -6.2029e-01,  2.8781e+00, -3.2431e-01,  2.2681e+00,  2.2189e+00,\n",
      "        -8.5741e-01, -6.8596e-01, -6.5262e-01, -4.7486e-01, -3.7237e-01,\n",
      "         5.5251e-02,  1.7302e+00,  2.5094e-01,  2.3580e+00, -4.8020e-01,\n",
      "         1.5118e+00,  2.0786e+00, -7.6820e-01,  2.7063e-01, -9.4728e-01,\n",
      "         1.0636e+00,  1.6407e-02,  5.5754e-02, -3.6759e-01,  5.7171e-03,\n",
      "         2.4741e+00,  8.0795e-01,  2.9077e-01, -5.7080e-01, -5.9557e-01,\n",
      "         1.5839e+00,  1.2598e+00, -1.7612e+00,  2.2352e+00,  3.8959e-01,\n",
      "         1.1030e+00, -6.1415e-02, -2.2489e+00, -3.2067e-01, -5.8788e-01,\n",
      "         1.1552e+00, -6.1745e-01, -2.1833e-01,  8.2649e-01, -3.6601e-02,\n",
      "         2.4404e+00,  2.5776e+00,  1.9090e+00, -3.5808e-01, -3.3993e-01,\n",
      "        -6.4513e-01,  2.2447e-01,  9.8325e-01, -1.9714e+00, -1.0911e+00,\n",
      "         3.9598e+00,  8.9052e-01,  1.0228e+00,  1.4359e+00, -1.2162e+00,\n",
      "         4.3783e-01,  2.2321e+00,  1.0488e+00,  1.9647e+00,  2.0174e+00,\n",
      "        -1.3436e+00,  1.1808e+00, -6.5796e-01,  1.2406e+00, -2.2683e-01,\n",
      "        -8.4098e-01,  3.0429e-01,  1.9534e-01, -1.2779e+00, -1.4446e+00,\n",
      "         6.4565e-01,  1.3535e-01,  1.6437e+00, -4.8362e-01, -1.7394e+00,\n",
      "         7.6917e-02, -3.4742e-01,  7.3461e-01, -5.1881e-01,  1.0559e+00,\n",
      "        -1.3157e+00, -4.6802e-01,  1.3514e+00, -1.8810e+00,  1.1823e+00,\n",
      "         9.3778e-01,  1.0286e+00,  2.7448e+00, -1.0410e+00, -1.3437e+00,\n",
      "         1.2987e+00, -8.4317e-01,  6.8452e-01,  3.0960e+00,  2.5452e-02,\n",
      "        -2.0344e+00,  7.1085e+00, -8.2863e-01,  1.0518e+00,  1.3529e+00,\n",
      "        -3.6204e-01,  2.9753e+00,  2.1643e-01, -2.5626e-02, -6.8564e-01,\n",
      "        -3.3215e+00, -1.4591e+00, -2.8118e+00,  3.9005e-01, -5.3059e-02,\n",
      "        -2.6188e+00,  9.4505e-01, -5.9028e-01,  3.3507e+00, -3.0074e+00,\n",
      "         5.0347e-01, -1.1629e-01, -2.2965e-01,  1.1536e+00, -8.5296e-01,\n",
      "         1.4464e+00,  2.0545e+00,  2.1666e-01, -4.4067e-01, -1.5210e+00,\n",
      "        -2.8773e-01, -1.5154e-01, -9.2765e-01,  9.4505e-01,  5.5285e-01,\n",
      "        -1.8323e+00,  2.8237e+00, -1.6298e+00,  9.5762e-01,  9.7984e-01,\n",
      "         1.1909e+00, -4.3268e-01, -1.3800e+00, -2.1664e-01, -1.0660e+00,\n",
      "        -7.1296e-01,  5.0144e-01,  2.4056e+00, -8.2098e-01, -1.6099e+00,\n",
      "         5.2077e-01, -1.0444e-01, -2.8953e+00,  1.4679e+00, -5.3160e-01,\n",
      "         2.8009e-01,  1.5335e+00, -3.7086e-01,  1.0149e+00, -2.0805e-01,\n",
      "        -5.5474e-01, -4.0695e-01, -1.5992e-01, -1.2185e+00, -9.9887e-01,\n",
      "        -1.4638e+00,  2.0881e+00,  2.6727e+00, -1.6416e+00,  5.6635e-01,\n",
      "        -1.5652e+00, -1.2777e-01,  2.0543e+00,  1.5596e+00, -1.5764e+00,\n",
      "         2.6293e+00, -9.0030e-01,  3.2040e+00,  8.8732e-01,  1.9689e+00,\n",
      "         7.0889e-01,  1.1879e-01, -5.6111e-01, -7.4514e-02,  9.9867e-01,\n",
      "        -6.3306e-01,  3.9870e+00, -1.3148e+00, -6.5925e-01,  7.6653e-01,\n",
      "         6.4862e-01,  3.2876e-01, -1.6961e+00,  4.6468e+00, -4.0353e-01,\n",
      "         2.0093e+00, -1.7806e+00, -1.1733e+00, -1.6096e+00,  1.6530e+00,\n",
      "         1.0309e+00,  1.0224e+00, -3.1491e-01,  1.4095e+00, -1.7907e+00,\n",
      "        -1.6949e+00,  5.0943e-02,  2.0061e+00, -8.5066e-01, -8.5342e-01,\n",
      "         4.6462e-01, -2.4170e-01,  1.9083e+00,  1.5845e+00,  5.6460e-01,\n",
      "         2.9488e+00, -9.2406e-01,  1.3244e+00,  6.4492e-01, -4.0358e-01,\n",
      "         9.9465e-01,  9.9322e-01,  3.6670e+00, -2.2346e+00,  1.2347e+00,\n",
      "        -3.2697e+00,  2.3127e+00,  1.4184e+00, -2.2892e+00,  2.0743e-01,\n",
      "         7.0403e+00,  1.6387e+00,  2.4659e-01,  1.3956e+00,  1.6453e+00,\n",
      "         7.3744e-01,  2.3842e+00,  1.7390e-02,  1.8303e+00,  1.3043e+00,\n",
      "        -1.4681e+00, -1.7963e+00,  7.1762e-01, -4.1016e-01,  5.1577e-01,\n",
      "        -1.7392e+00, -1.8767e+00, -1.4445e+00, -4.1270e-01,  2.8185e+00,\n",
      "         3.5014e-01,  1.7557e+00, -2.0111e-01,  1.1996e+00, -1.1476e-01,\n",
      "         1.6543e+00,  9.0470e-01, -3.0188e-01, -9.9864e-01,  2.6794e+00,\n",
      "        -7.3663e-01,  3.0264e+00,  4.0913e+00, -1.2723e-01, -1.2504e+00,\n",
      "        -6.7237e-01,  1.1770e+00,  1.7567e+00,  3.2672e-01,  5.9785e-01,\n",
      "        -9.6403e-01,  7.8904e-01,  1.7051e+00,  7.4587e-01, -6.1828e-01,\n",
      "         8.9256e-01,  1.3339e+00,  5.5367e+00, -1.2471e+00,  3.1171e-02,\n",
      "        -1.0287e+00, -2.4069e-01,  1.0836e-01,  3.5093e-03, -6.9036e-02,\n",
      "         3.7772e-01,  2.2401e+00,  6.2513e-01, -1.2094e-01, -1.5716e+00,\n",
      "         1.2317e+00, -4.8075e-01, -2.0402e+00,  2.3930e+00,  5.7955e-01,\n",
      "        -1.1531e+00,  1.6574e+00,  5.2358e-01, -4.0185e-01, -2.8881e+00,\n",
      "         1.8818e-01,  2.2689e+00, -3.0451e+00,  4.1469e-01,  2.4981e+00,\n",
      "         1.3542e+00, -5.6485e-01,  3.6389e+00,  1.0113e+00,  3.3929e-02,\n",
      "         2.1510e+00, -6.9888e-01,  3.2338e-01, -1.2887e-01, -8.8050e-01,\n",
      "         5.0570e-01,  4.0903e-01,  2.1152e+00, -5.6314e-01,  8.0646e-01,\n",
      "        -5.3934e-01,  5.9272e-01,  2.9761e-01,  3.5518e+00,  1.7725e+00,\n",
      "        -1.0067e+00, -1.2810e+00,  1.1322e+00,  9.3055e-03,  7.7683e-01,\n",
      "        -1.3876e+00,  2.6801e+00,  2.1267e+00,  4.3035e-01,  3.5257e+00,\n",
      "         7.0653e-01,  2.5220e+00, -8.5950e-01,  5.6071e-01, -1.3835e+00,\n",
      "        -1.1753e+00,  2.5345e+00,  7.8288e-03,  5.4526e-01, -9.5372e-01,\n",
      "        -4.7580e-01,  1.1707e+00, -1.1744e+00,  1.4196e+00,  9.7737e-01,\n",
      "        -5.2565e-01, -1.2744e-01, -2.1004e+00, -2.1925e+00,  3.9138e-01,\n",
      "         1.6793e+00, -1.0881e+00, -9.3099e-01, -1.2949e+00, -7.9923e-02,\n",
      "        -2.7205e-01, -7.1479e-02,  1.2218e+00,  6.9027e-02,  1.0203e+00,\n",
      "         7.4357e-03, -3.0303e-01, -1.5037e+00,  4.2844e-01,  3.9005e-01,\n",
      "        -5.0202e-02, -1.2256e+00,  2.7511e-01, -1.0350e+00, -2.5225e-01,\n",
      "        -1.8637e+00, -5.8765e-01, -8.9166e-01,  3.5296e-01,  1.0678e-01,\n",
      "        -4.3653e-01, -9.0070e-01, -6.9081e-01, -7.3163e-01,  8.8490e-01,\n",
      "        -1.8160e+00, -7.0033e-01, -2.0604e-01, -7.7470e-01, -4.0609e-01,\n",
      "        -5.8128e-01,  3.0849e+00, -1.3145e+00,  1.1214e+00, -6.0701e-01,\n",
      "        -1.7341e+00,  4.3384e-01, -4.3337e-01, -1.4985e+00, -2.3947e+00,\n",
      "         1.1340e+00, -1.5906e+00,  8.2108e-01,  3.5230e-01, -1.2079e+00,\n",
      "        -2.2028e+00,  4.0478e-01,  4.8852e-01,  1.0641e-01, -1.4534e+00,\n",
      "        -2.5371e+00, -3.5063e+00,  1.7181e+00, -1.6002e+00, -1.3963e+00,\n",
      "        -9.6516e-01, -1.1133e+00, -1.7567e+00, -1.2310e+00, -4.5211e-01,\n",
      "        -4.4010e-01,  4.9620e-01, -1.4497e+00,  1.2562e+00,  2.6699e-01])\n",
      "tensor([1.5874e-07, 1.2054e-08, 1.3712e-08, 1.0038e-07, 1.2695e-08, 3.2550e-08,\n",
      "        7.0563e-09, 1.7332e-07, 2.6392e-07, 9.5912e-08, 3.9236e-08, 1.5812e-08,\n",
      "        8.4527e-09, 1.6110e-08, 1.0267e-08, 7.6524e-09, 3.1134e-08, 1.4081e-07,\n",
      "        3.6309e-08, 2.7582e-08, 5.4094e-09, 4.6463e-08, 1.1260e-08, 4.9246e-08,\n",
      "        5.0531e-09, 6.3242e-08, 7.0237e-09, 9.4294e-09, 1.6379e-08, 1.8714e-08,\n",
      "        1.1963e-08, 1.1006e-08, 7.6581e-09, 1.2699e-07, 5.7482e-08, 1.0521e-07,\n",
      "        4.7446e-08, 5.5521e-08, 6.9939e-08, 4.0486e-08, 3.0893e-08, 1.8417e-08,\n",
      "        4.5760e-08, 4.4250e-08, 7.5670e-08, 9.6960e-08, 2.1435e-08, 2.4228e-08,\n",
      "        8.2725e-09, 1.6410e-08, 2.5785e-07, 1.3089e-07, 5.8830e-08, 1.3802e-08,\n",
      "        1.6072e-07, 2.4320e-08, 9.7310e-09, 2.3493e-08, 6.5275e-08, 5.1120e-08,\n",
      "        3.1947e-07, 1.8767e-07, 1.3437e-07, 1.9110e-07, 1.2923e-08, 1.3134e-07,\n",
      "        7.5159e-08, 4.1553e-08, 6.8780e-08, 1.6681e-08, 2.8231e-08, 5.4465e-07,\n",
      "        9.9972e-09, 1.2305e-08, 1.9682e-08, 5.7073e-09, 2.0278e-08, 6.5088e-08,\n",
      "        1.3059e-07, 5.1334e-08, 1.1228e-07, 2.9355e-09, 1.9874e-08, 5.2924e-08,\n",
      "        8.6143e-08, 1.1117e-08, 2.1911e-08, 6.8661e-09, 1.4829e-08, 8.9952e-09,\n",
      "        1.9857e-08, 6.2147e-08, 3.4201e-08, 2.3565e-08, 2.0565e-08, 1.8559e-08,\n",
      "        1.0292e-08, 1.3291e-07, 3.7289e-08, 1.0350e-07, 1.4474e-07, 5.2681e-08,\n",
      "        5.4152e-09, 3.4976e-08, 8.9237e-07, 1.4615e-08, 2.6742e-07, 1.5642e-08,\n",
      "        3.9232e-08, 4.1407e-08, 5.5453e-09, 6.7372e-08, 2.9908e-07, 5.3209e-08,\n",
      "        1.1726e-07, 3.2959e-08, 1.2585e-07, 2.4316e-08, 2.0441e-07, 4.2634e-08,\n",
      "        1.0943e-08, 9.5474e-08, 2.0852e-07, 4.6419e-08, 1.1525e-07, 9.6297e-09,\n",
      "        7.0144e-08, 3.8861e-08, 1.6372e-08, 1.8664e-08, 2.4870e-08, 1.0013e-08,\n",
      "        4.1373e-09, 3.6101e-07, 1.5091e-08, 6.8625e-09, 1.3628e-07, 1.6247e-08,\n",
      "        1.2067e-08, 1.2350e-08, 6.3827e-09, 3.0569e-09, 6.6200e-08, 2.7637e-08,\n",
      "        2.1945e-08, 4.5518e-08, 1.8959e-08, 1.9314e-08, 1.6628e-08, 2.9681e-09,\n",
      "        1.0408e-07, 4.9603e-06, 5.2596e-08, 1.7032e-08, 1.4391e-07, 5.8430e-08,\n",
      "        7.4649e-08, 8.3652e-08, 1.4743e-06, 1.4186e-05, 4.6627e-06, 4.4479e-06,\n",
      "        1.1164e-06, 4.1829e-04, 1.9019e-06, 6.1377e-06, 4.0105e-07, 5.7122e-06,\n",
      "        2.2570e-06, 3.8250e-06, 1.5142e-05, 7.4844e-08, 8.4679e-07, 5.2499e-06,\n",
      "        4.2399e-05, 7.1000e-05, 2.4291e-06, 6.6585e-07, 1.3771e-07, 1.0522e-06,\n",
      "        4.1273e-06, 1.8667e-07, 2.8938e-05, 2.5711e-07, 2.5112e-05, 4.3187e-05,\n",
      "        9.9506e-05, 1.5848e-06, 1.3250e-05, 1.1610e-04, 1.1853e-07, 2.6294e-04,\n",
      "        6.0243e-06, 2.8858e-04, 3.3232e-06, 2.7478e-06, 4.3294e-07, 2.5840e-06,\n",
      "        7.6230e-07, 1.1999e-05, 1.6600e-06, 3.9162e-06, 3.0073e-06, 1.4665e-07,\n",
      "        2.5548e-07, 9.7347e-07, 8.8540e-07, 6.8565e-06, 1.2920e-06, 4.6444e-06,\n",
      "        2.9631e-08, 6.6434e-07, 9.7248e-08, 2.5280e-06, 5.3606e-06, 2.7263e-07,\n",
      "        1.1317e-06, 1.2505e-07, 1.0087e-06, 1.8363e-06, 2.6957e-06, 1.5582e-07,\n",
      "        2.3197e-06, 1.3291e-06, 1.4838e-05, 5.4988e-04, 2.2663e-05, 1.2864e-04,\n",
      "        1.3603e-07, 6.0549e-07, 8.3403e-07, 1.3079e-05, 2.3674e-06, 1.1842e-06,\n",
      "        6.2025e-05, 9.9630e-01, 1.2311e-05, 4.2143e-07, 1.1225e-06, 5.3987e-07,\n",
      "        7.0615e-06, 2.1497e-07, 1.0622e-07, 8.2987e-06, 2.1629e-05, 5.4228e-07,\n",
      "        5.8548e-06, 7.1301e-06, 1.9329e-05, 6.3091e-06, 4.2183e-06, 1.4106e-07,\n",
      "        9.2020e-08, 8.5321e-07, 2.7433e-07, 5.5712e-05, 3.3898e-06, 1.6801e-07,\n",
      "        9.8998e-08, 5.2457e-07, 6.5924e-06, 1.0862e-06, 4.7808e-06, 1.0593e-05,\n",
      "        3.3412e-05, 1.1740e-07, 2.5639e-07, 1.1571e-06, 4.2260e-07, 1.7127e-06,\n",
      "        5.3424e-07, 7.5241e-06, 2.5124e-07, 1.5606e-05, 7.5084e-06, 2.2845e-06,\n",
      "        2.5297e-07, 2.1239e-07, 4.1275e-07, 1.1776e-08, 2.1925e-07, 3.0504e-06,\n",
      "        1.5922e-06, 1.3434e-07, 1.7248e-06, 8.6097e-07, 2.5650e-07, 8.5833e-08,\n",
      "        7.0711e-08, 2.7915e-08, 5.5133e-08, 2.1561e-06, 2.7063e-07, 7.7479e-08,\n",
      "        3.1065e-07, 2.3215e-07, 6.5695e-08, 9.3676e-09, 8.6890e-09, 5.1617e-08,\n",
      "        3.1276e-08, 1.6422e-08, 5.0008e-08, 3.7736e-08, 5.0162e-08, 8.2820e-08,\n",
      "        7.2894e-08, 1.9383e-08, 1.7250e-08, 1.0296e-07, 1.0793e-08, 1.0247e-07,\n",
      "        9.9259e-08, 2.7190e-08, 3.9580e-07, 1.0081e-08, 1.7979e-08, 4.1856e-08,\n",
      "        1.0774e-08, 1.5238e-08, 1.1417e-08, 8.7157e-08, 1.2337e-08, 1.7458e-08,\n",
      "        4.6349e-09, 1.9669e-08, 3.4186e-08, 1.5272e-07, 3.1361e-08, 4.5128e-08,\n",
      "        2.9478e-08, 8.9103e-07, 3.8955e-08, 7.4259e-08, 6.5799e-09, 1.3642e-08,\n",
      "        2.6951e-08, 1.1881e-07, 1.0698e-07, 4.7255e-08, 1.3697e-07, 4.1342e-07,\n",
      "        2.1042e-07, 1.2223e-08, 1.4073e-08, 2.7207e-08, 1.0084e-07, 2.5571e-08,\n",
      "        6.6759e-08, 1.2133e-08, 9.6827e-08, 1.0585e-07, 4.3033e-08, 6.0269e-08,\n",
      "        5.0894e-07, 5.4508e-07, 2.0567e-07, 6.4042e-08, 1.0751e-07, 2.1026e-07,\n",
      "        3.1201e-08, 1.2888e-08, 7.5786e-08, 5.2965e-08, 3.5504e-08, 3.6316e-08,\n",
      "        3.8068e-09, 4.1690e-08, 1.3355e-07, 1.5555e-08, 1.5278e-08, 3.7793e-08,\n",
      "        1.6809e-08, 4.3373e-08, 6.6463e-09, 9.3372e-09, 2.9620e-08, 5.5902e-09,\n",
      "        2.4243e-07, 9.7682e-08, 6.2413e-09, 1.4022e-08, 1.0972e-08, 5.5044e-09,\n",
      "        9.7184e-08, 1.1250e-07, 1.0628e-08, 8.2694e-09, 9.0802e-08, 1.7710e-07,\n",
      "        9.7747e-08, 5.5055e-08, 1.0967e-07, 3.2554e-09, 1.4978e-07, 6.9227e-08,\n",
      "        2.5779e-08, 3.9715e-09, 4.5987e-08, 2.9936e-07, 1.1243e-06, 2.1847e-07,\n",
      "        1.5401e-07, 1.2434e-07, 3.0853e-08, 9.6196e-08, 1.5494e-07, 5.4946e-08,\n",
      "        3.3252e-07, 6.9014e-07, 2.2116e-08, 1.7343e-07, 1.3890e-06, 3.3550e-07,\n",
      "        5.8854e-06, 4.8962e-08, 5.6855e-08, 6.4098e-07, 1.8465e-07, 7.5577e-08,\n",
      "        4.4271e-07, 4.4383e-07, 4.2201e-07, 1.1117e-07, 3.9372e-08, 2.9939e-08,\n",
      "        1.7608e-07, 5.1927e-07, 5.6624e-06, 2.5462e-06, 4.9531e-07, 5.7756e-07,\n",
      "        1.2258e-08, 1.6749e-06, 9.0201e-07, 6.0191e-07, 9.9471e-08, 2.6915e-07,\n",
      "        1.1190e-07, 7.7377e-07, 3.0229e-07, 5.2416e-08, 1.6023e-07, 4.0035e-07,\n",
      "        1.0810e-07, 3.0021e-07, 4.1380e-07, 2.4072e-07, 1.5310e-07, 1.5937e-07,\n",
      "        1.7198e-07, 2.8737e-07, 2.9563e-07, 8.2936e-07, 5.2912e-07, 2.0021e-07,\n",
      "        4.3922e-08, 2.3048e-06, 4.1522e-07, 6.3062e-07, 4.8802e-07, 1.3531e-07,\n",
      "        1.5696e-07, 2.7945e-06, 5.7403e-07, 5.8116e-05, 6.5725e-08, 3.6129e-07,\n",
      "        1.7691e-07, 2.5611e-07, 2.4341e-07, 2.4326e-07, 6.4371e-07, 1.5528e-07,\n",
      "        4.6846e-08, 3.1964e-07, 2.0378e-08, 6.2615e-08, 1.5028e-07, 1.3497e-06,\n",
      "        1.3041e-07, 2.8120e-07, 5.9884e-07, 2.7734e-07, 1.1042e-07, 5.7135e-07,\n",
      "        2.0928e-08, 1.7109e-05, 7.4820e-07, 6.4992e-08, 2.0629e-07, 2.2163e-07,\n",
      "        1.3673e-07, 1.8217e-07, 7.2678e-08, 1.4429e-07, 1.7593e-07, 1.6336e-07,\n",
      "        1.4507e-08, 4.5161e-07, 2.9919e-08, 8.2679e-08, 1.9401e-06, 1.8881e-07,\n",
      "        2.2386e-07, 3.7753e-07, 3.6274e-07, 2.6071e-07, 1.5592e-06, 6.2327e-08,\n",
      "        2.6486e-06, 1.0825e-07, 8.4951e-07, 3.2246e-07, 6.8551e-06, 3.8561e-06,\n",
      "        3.6800e-07, 6.5093e-07, 4.2852e-06, 4.0196e-07, 1.2363e-07, 3.1536e-07,\n",
      "        3.6258e-07, 4.7932e-07, 1.3635e-07, 4.0407e-08, 3.8358e-07, 5.8372e-07,\n",
      "        1.2310e-07, 7.2830e-08, 6.6958e-07, 4.1928e-06, 8.4522e-07, 2.1471e-07,\n",
      "        1.3906e-07, 1.2219e-07, 2.1006e-06, 5.3357e-06, 2.0080e-07, 5.9520e-06,\n",
      "        7.0641e-08, 1.3258e-06, 1.8747e-07, 6.7226e-06, 2.0704e-06, 2.1058e-07,\n",
      "        7.1415e-07, 3.1541e-08, 2.9743e-07, 1.2898e-07, 4.5817e-08, 5.3356e-07,\n",
      "        1.4888e-06, 2.4043e-07, 8.1718e-08, 1.7191e-08, 8.1701e-07, 3.0580e-07,\n",
      "        3.0212e-08, 3.2814e-06, 3.4730e-07, 1.2157e-07, 5.0959e-07, 3.2335e-07,\n",
      "        2.0189e-08, 1.9901e-07, 1.4835e-07, 6.0861e-06, 9.3970e-07, 4.6167e-08,\n",
      "        4.9973e-07, 1.7632e-08, 7.2281e-07, 6.8663e-08, 2.8764e-06, 1.1133e-07,\n",
      "        3.6807e-06, 1.4967e-07, 1.9999e-06, 1.9039e-06, 8.7823e-08, 1.0425e-07,\n",
      "        1.0778e-07, 1.2875e-07, 1.4265e-07, 2.1876e-07, 1.1678e-06, 2.6605e-07,\n",
      "        2.1880e-06, 1.2806e-07, 9.3874e-07, 1.6547e-06, 9.6018e-08, 2.7134e-07,\n",
      "        8.0275e-08, 5.9966e-07, 2.1043e-07, 2.1887e-07, 1.4333e-07, 2.0819e-07,\n",
      "        2.4574e-06, 4.6437e-07, 2.7686e-07, 1.1697e-07, 1.1411e-07, 1.0089e-06,\n",
      "        7.2962e-07, 3.5572e-08, 1.9351e-06, 3.0562e-07, 6.2372e-07, 1.9467e-07,\n",
      "        2.1843e-08, 1.5022e-07, 1.1499e-07, 6.5720e-07, 1.1164e-07, 1.6640e-07,\n",
      "        4.7306e-07, 1.9956e-07, 2.3758e-06, 2.7254e-06, 1.3965e-06, 1.4470e-07,\n",
      "        1.4735e-07, 1.0859e-07, 2.5910e-07, 5.5335e-07, 2.8827e-08, 6.9523e-08,\n",
      "        1.0856e-05, 5.0434e-07, 5.7570e-07, 8.7013e-07, 6.1350e-08, 3.2072e-07,\n",
      "        1.9292e-06, 5.9084e-07, 1.4765e-06, 1.5565e-06, 5.4011e-08, 6.7420e-07,\n",
      "        1.0721e-07, 7.1574e-07, 1.6499e-07, 8.9279e-08, 2.8063e-07, 2.5166e-07,\n",
      "        5.7675e-08, 4.8818e-08, 3.9480e-07, 2.3701e-07, 1.0711e-06, 1.2763e-07,\n",
      "        3.6355e-08, 2.2355e-07, 1.4625e-07, 4.3154e-07, 1.2321e-07, 5.9503e-07,\n",
      "        5.5539e-08, 1.2963e-07, 7.9964e-07, 3.1555e-08, 6.7522e-07, 5.2875e-07,\n",
      "        5.7903e-07, 3.2212e-06, 7.3090e-08, 5.4005e-08, 7.5855e-07, 8.9084e-08,\n",
      "        4.1045e-07, 4.5769e-06, 2.1234e-07, 2.7067e-08, 2.5301e-04, 9.0388e-08,\n",
      "        5.9260e-07, 8.0080e-07, 1.4413e-07, 4.0562e-06, 2.5702e-07, 2.0177e-07,\n",
      "        1.0428e-07, 7.4723e-09, 4.8117e-08, 1.2440e-08, 3.0576e-07, 1.9631e-07,\n",
      "        1.5089e-08, 5.3261e-07, 1.1472e-07, 5.9041e-06, 1.0230e-08, 3.4248e-07,\n",
      "        1.8428e-07, 1.6453e-07, 6.5611e-07, 8.8215e-08, 8.7928e-07, 1.6152e-06,\n",
      "        2.5708e-07, 1.3323e-07, 4.5229e-08, 1.5525e-07, 1.7790e-07, 8.1867e-08,\n",
      "        5.3261e-07, 3.5982e-07, 3.3129e-08, 3.4857e-06, 4.0565e-08, 5.3935e-07,\n",
      "        5.5147e-07, 6.8104e-07, 1.3430e-07, 5.2076e-08, 1.6668e-07, 7.1292e-08,\n",
      "        1.0147e-07, 3.4178e-07, 2.2946e-06, 9.1082e-08, 4.1383e-08, 3.4846e-07,\n",
      "        1.8647e-07, 1.1443e-08, 8.9845e-07, 1.2165e-07, 2.7392e-07, 9.5937e-07,\n",
      "        1.4286e-07, 5.7113e-07, 1.6812e-07, 1.1887e-07, 1.3780e-07, 1.7641e-07,\n",
      "        6.1207e-08, 7.6239e-08, 4.7890e-08, 1.6705e-06, 2.9972e-06, 4.0092e-08,\n",
      "        3.6470e-07, 4.3275e-08, 1.8218e-07, 1.6149e-06, 9.8467e-07, 4.2792e-08,\n",
      "        2.8698e-06, 8.4136e-08, 5.0987e-06, 5.0273e-07, 1.4827e-06, 4.2058e-07,\n",
      "        2.3311e-07, 1.1811e-07, 1.9214e-07, 5.6195e-07, 1.0991e-07, 1.1156e-05,\n",
      "        5.5588e-08, 1.0707e-07, 4.4553e-07, 3.9598e-07, 2.8758e-07, 3.7962e-08,\n",
      "        2.1581e-05, 1.3827e-07, 1.5439e-06, 3.4889e-08, 6.4036e-08, 4.1393e-08,\n",
      "        1.0811e-06, 5.8033e-07, 5.7545e-07, 1.5108e-07, 8.4742e-07, 3.4536e-08,\n",
      "        3.8009e-08, 2.1782e-07, 1.5389e-06, 8.8418e-08, 8.8174e-08, 3.2943e-07,\n",
      "        1.6256e-07, 1.3955e-06, 1.0095e-06, 3.6407e-07, 3.9502e-06, 8.2161e-08,\n",
      "        7.7835e-07, 3.9452e-07, 1.3826e-07, 5.5969e-07, 5.5889e-07, 8.1011e-06,\n",
      "        2.2157e-08, 7.1157e-07, 7.8699e-09, 2.0911e-06, 8.5502e-07, 2.0980e-08,\n",
      "        2.5472e-07, 2.3634e-04, 1.0658e-06, 2.6490e-07, 8.3572e-07, 1.0728e-06,\n",
      "        4.3276e-07, 2.2461e-06, 2.1064e-07, 1.2909e-06, 7.6280e-07, 4.7688e-08,\n",
      "        3.4343e-08, 4.2426e-07, 1.3736e-07, 3.4672e-07, 3.6362e-08, 3.1692e-08,\n",
      "        4.8826e-08, 1.3701e-07, 3.4677e-06, 2.9380e-07, 1.1980e-06, 1.6929e-07,\n",
      "        6.8702e-07, 1.8456e-07, 1.0825e-06, 5.1155e-07, 1.5306e-07, 7.6256e-08,\n",
      "        3.0174e-06, 9.9099e-08, 4.2689e-06, 1.2382e-05, 1.8227e-07, 5.9282e-08,\n",
      "        1.0568e-07, 6.7163e-07, 1.1992e-06, 2.8699e-07, 3.7638e-07, 7.8942e-08,\n",
      "        4.5568e-07, 1.1389e-06, 4.3642e-07, 1.1155e-07, 5.0538e-07, 7.8577e-07,\n",
      "        5.2544e-05, 5.9483e-08, 2.1356e-07, 7.3996e-08, 1.6272e-07, 2.3070e-07,\n",
      "        2.0773e-07, 1.9320e-07, 3.0201e-07, 1.9446e-06, 3.8679e-07, 1.8342e-07,\n",
      "        4.2999e-08, 7.0940e-07, 1.2799e-07, 2.6911e-08, 2.2660e-06, 3.6955e-07,\n",
      "        6.5343e-08, 1.0859e-06, 3.4943e-07, 1.3850e-07, 1.1527e-08, 2.4987e-07,\n",
      "        2.0014e-06, 9.8516e-09, 3.1338e-07, 2.5170e-06, 8.0186e-07, 1.1767e-07,\n",
      "        7.8763e-06, 5.6910e-07, 2.1415e-07, 1.7789e-06, 1.0291e-07, 2.8604e-07,\n",
      "        1.8198e-07, 8.5819e-08, 3.4325e-07, 3.1161e-07, 1.7163e-06, 1.1787e-07,\n",
      "        4.6368e-07, 1.2071e-07, 3.7445e-07, 2.7876e-07, 7.2191e-06, 1.2184e-06,\n",
      "        7.5645e-08, 5.7499e-08, 6.4224e-07, 2.0894e-07, 4.5015e-07, 5.1682e-08,\n",
      "        3.0194e-06, 1.7361e-06, 3.1833e-07, 7.0332e-06, 4.1959e-07, 2.5778e-06,\n",
      "        8.7640e-08, 3.6266e-07, 5.1893e-08, 6.3909e-08, 2.6103e-06, 2.0863e-07,\n",
      "        3.5710e-07, 7.9760e-08, 1.2863e-07, 6.6743e-07, 6.3964e-08, 8.5603e-07,\n",
      "        5.5011e-07, 1.2237e-07, 1.8224e-07, 2.5339e-08, 2.3109e-08, 3.0616e-07,\n",
      "        1.1099e-06, 6.9732e-08, 8.1594e-08, 5.6706e-08, 1.9110e-07, 1.5770e-07,\n",
      "        1.9272e-07, 7.0244e-07, 2.2180e-07, 5.7422e-07, 2.0855e-07, 1.5289e-07,\n",
      "        4.6019e-08, 3.1772e-07, 3.0576e-07, 1.9687e-07, 6.0775e-08, 2.7256e-07,\n",
      "        7.3533e-08, 1.6085e-07, 3.2107e-08, 1.1502e-07, 8.4866e-08, 2.9463e-07,\n",
      "        2.3033e-07, 1.3378e-07, 8.4103e-08, 1.0374e-07, 9.9595e-08, 5.0152e-07,\n",
      "        3.3675e-08, 1.0276e-07, 1.6846e-07, 9.5396e-08, 1.3792e-07, 1.1575e-07,\n",
      "        4.5261e-06, 5.5601e-08, 6.3530e-07, 1.1281e-07, 3.6548e-08, 3.1944e-07,\n",
      "        1.3420e-07, 4.6258e-08, 1.8879e-08, 6.4341e-07, 4.2189e-08, 4.7051e-07,\n",
      "        2.9443e-07, 6.1857e-08, 2.2873e-08, 3.1029e-07, 3.3740e-07, 2.3025e-07,\n",
      "        4.8390e-08, 1.6373e-08, 6.2116e-09, 1.1538e-06, 4.1787e-08, 5.1237e-08,\n",
      "        7.8852e-08, 6.7997e-08, 3.5732e-08, 6.0446e-08, 1.3171e-07, 1.3331e-07,\n",
      "        3.4000e-07, 4.8573e-08, 7.2698e-07, 2.7035e-07])\n"
     ]
    }
   ],
   "source": [
    "# sample execution (requires torchvision)\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "input_image = Image.open(filename)\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "input_tensor = preprocess(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "\n",
    "# move the input and model to GPU for speed if available\n",
    "if torch.cuda.is_available():\n",
    "    input_batch = input_batch.to('cuda')\n",
    "    model.to('cuda')\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(input_batch)\n",
    "# Tensor of shape 1000, with confidence scores over Imagenet's 1000 classes\n",
    "print(output[0])\n",
    "# The output has unnormalized scores. To get probabilities, you can run a softmax on it.\n",
    "probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "print(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('imagenet_classes.txt', <http.client.HTTPMessage at 0x7fa55d5f4ca0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download ImageNet labels\n",
    "import urllib.request\n",
    "url = 'https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt'\n",
    "filename = 'imagenet_classes.txt'\n",
    "urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(235) German shepherd 0.9963040351867676\n",
      "tensor(225) malinois 0.0005498826503753662\n",
      "tensor(163) bloodhound 0.00041828895336948335\n",
      "tensor(193) Australian terrier 0.0002885849680751562\n",
      "tensor(191) Airedale 0.000262939342064783\n"
     ]
    }
   ],
   "source": [
    "# Read the categories\n",
    "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
    "    categories = [s.strip() for s in f.readlines()]\n",
    "# Show top categories per image\n",
    "top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
    "for i in range(top5_prob.size(0)):\n",
    "    print(top5_catid[i], categories[top5_catid[i]], top5_prob[i].item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
